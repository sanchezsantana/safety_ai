# QA Layer Agent â€“ Mining Safety

This repository defines the architecture and strategy for a **Question Answering (QA) Agent** that integrates multiple information sources and predictive models for mining safety. The system leverages **LangChain**, **LlamaIndex**, **Neo4j AuraDB**, **Qdrant**, **Gemma 3B Finetuned**, and an initial frontend in **Streamlit**.

---

## ğŸš€ Objective
Design an agent capable of answering natural language questions in a **robust, explainable, and scalable** way, combining:
- Semantic retrieval from multiple **Vector Databases (VDBs)**.
- Structured queries in a **Graph Database (GDB)**.
- Inference from **predictive models** exposed via API.
- Reasoning and final answer generation using a **finetuned LLM (Gemma 3B)**.

---

## ğŸ§© Core Components

### 1. Central LLM
- **Gemma 3B finetuned** as the agentâ€™s reasoning engine.
- Roles: tool selection, multi-source reasoning, and final response generation.

### 2. Vector Databases (VDBs)
- **Qdrant** as the vector store backend.
- Managed through **LlamaIndex** with `BAAI/bge-m3` embeddings.
- At least **3 collections**:
  - **Ontology VDB** â€“ domain ontology (risks, causes, controls, etc.).
  - **Technical Docs VDB** â€“ structured mining safety documents.
  - **Synthetic Data VDB** â€“ generated incident/observation data (later real operational data).
- Query orchestration with **RouterQueryEngine**.

### 3. Graph Database (GDB)
- **Neo4j AuraDB**.
- Cypher queries via LangChain (`GraphCypherQAChain`) or `py2neo`.
- Used for structured relationships: roles â†’ tasks â†’ risks â†’ controls â†’ consequences.

### 4. Predictive Models
- Exposed as **REST APIs** (FastAPI).
- Input: operational features, risk indicators.
- Output: prediction score, probability, and explainability factors (e.g., SHAP values).
- Integrated as LangChain tools.

### 5. Frontend
- **Streamlit** as the MVP user interface.
- Communicates with backend through API endpoints.
- Designed to be replaceable by enterprise dashboards without changing backend logic.

---

## âš™ï¸ Orchestration Strategy

The agent follows a **multi-source orchestration pattern**:

```mermaid
flowchart TD
    A[User Query - Streamlit] --> B[QA Layer Agent - LangChain + Gemma 3B]
    B -->|Semantic Search| C[Ontology VDB - Qdrant]
    B -->|Semantic Search| D[Technical Docs VDB - Qdrant]
    B -->|Semantic Search| E[Synthetic Data VDB - Qdrant]
    B -->|Graph Reasoning| F[GDB - Neo4j AuraDB]
    B -->|Predictions| G[Predictive Models API]
    B --> H[Answer Fusion + Reasoning]
    H --> I[Final Response + Evidence]
    I --> A
```

### Execution Flow
1. **User query** enters via Streamlit.  
2. **Intent classification**: router (embedding-based or heuristic) determines relevant source(s).  
3. **Tool invocation**: LangChain agent calls VDB, GDB, predictive API, or a combination.  
4. **Result normalization**: all results converted into JSON with schema:
   ```json
   {
     "source": "Ontology VDB",
     "content": "...",
     "confidence": 0.89
   }
   ```
5. **Fusion & reasoning**: Gemma 3B integrates normalized results and generates the final response.  
6. **Explainability**: alongside the answer, the system outputs supporting evidence (chunks, Cypher queries, prediction logs).  

---

## ğŸ” Robustness & Best Practices

1. **Router Layer**  
   - Lightweight intent classifier avoids overloading the LLM with trivial decisions.  

2. **Unified Result Schema**  
   - Multi-source outputs normalized into JSON for consistency.  

3. **Fallbacks**  
   - If a source is unavailable (e.g., Neo4j timeout), the agent responds with available context + disclaimer.  

4. **Logging & Traceability**  
   - Every query logs: tools invoked, response times, evidence returned.  

5. **Explainability First**  
   - Essential for mining safety: each answer includes the *why* and *how* behind it.  

6. **Sub-Agents Architecture**  
   - Specialized sub-agents (Graph agent, Predictive agent, VDB agent).  
   - A **master agent** coordinates calls.  

---

## ğŸ› ï¸ Tech Stack

- **LLM**: Gemma 3B finetuned (via [Unsloth](https://github.com/unslothai/unsloth)).  
- **LangChain**: orchestration & multi-tool agent.  
- **LlamaIndex**: VDB management, RouterQueryEngine.  
- **Qdrant**: vector store (3 collections: ontology, docs, synthetic data).  
- **Neo4j AuraDB**: knowledge graph.  
- **FastAPI**: predictive model microservices.  
- **Streamlit**: initial UI.  
- **Embeddings**: `BAAI/bge-m3`.  

---

## ğŸ“Œ Roadmap

- [x] Setup of 3 Qdrant VDBs (ontology, docs, synthetic data).  
- [x] Integrate Gemma 3B FT with LangChain.  
- [ ] Implement RouterQueryEngine with intent classifier.  
- [ ] Deploy predictive models as FastAPI services.  
- [ ] Normalize multi-source outputs into JSON schema.  
- [ ] Build explainability layer (retrieved chunks, Cypher, SHAP).  
- [ ] Migrate Streamlit MVP â†’ enterprise-ready dashboard.  

---

## ğŸ“‚ Suggested Repo Structure

```plaintext
â”œâ”€â”€ README.md
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ main_agent.py          # QA Layer Agent logic
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ vdb_tool.py        # Qdrant retrieval
â”‚   â”‚   â”œâ”€â”€ gdb_tool.py        # Neo4j connector
â”‚   â”‚   â”œâ”€â”€ predictive_tool.py # API wrapper
â”‚   â””â”€â”€ router.py              # Intent classifier
â”œâ”€â”€ models_api/
â”‚   â””â”€â”€ app.py                 # FastAPI app for predictive models
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ exploration.ipynb
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ streamlit_app.py
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ qdrant/
â”‚   â”œâ”€â”€ docstore.json
â”‚   â””â”€â”€ index_store.json
```

---

## ğŸ“– Example Usage

```bash
# Start predictive model API
uvicorn models_api.app:app --reload

# Run the agent
python agent/main_agent.py

# Launch frontend
streamlit run frontend/streamlit_app.py
```

Example user queries:  
- â€œWhat are the critical controls active in the Concentrator Plant?â€  
- â€œWhat is the probability of a fall-from-height incident this week?â€  
- â€œWhich historical trajectory led to similar near-miss events?â€  

---

